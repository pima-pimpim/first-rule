# app.py
import json
import pandas as pd
import streamlit as st

st.set_page_config(page_title="JSON ‚Üí Table with Dropdowns", layout="wide")
st.title("üìÑ JSON ‚Üí Dropdown Filter ‚Üí Table")

# -------- ‡πÇ‡∏´‡∏•‡∏î JSON --------
col1, col2 = st.columns(2)
data = None

with col1:
    f = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå JSON", type=["json"])
    if f:
        data = json.load(f)

with col2:
    txt = st.text_area("‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏≤‡∏á JSON ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà", height=160, placeholder='‡πÄ‡∏ä‡πà‡∏ô [{"date":"2025-10-01","cat":"A","value":10}, ...]')
    if txt.strip():
        try:
            data = json.loads(txt)
        except Exception as e:
            st.error(f"‡∏≠‡πà‡∏≤‡∏ô JSON ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")

if data is None:
    st.info("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏≤‡∏á JSON ‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏∞")
    st.stop()

# -------- ‡πÅ‡∏õ‡∏•‡∏á JSON ‚Üí DataFrame (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö nested) --------
try:
    df = pd.json_normalize(data, sep=".")
except Exception:
    df = pd.DataFrame(data)

if df.empty:
    st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÑ‡∏î‡πâ")
    st.stop()

# -------- helper: ‡∏ó‡∏≥‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ô‡∏±‡∏ö unique ‡πÑ‡∏î‡πâ‡πÄ‡∏™‡∏°‡∏≠ --------
def _serialize_cell(x):
    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ list/dict/set ‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô string ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ
    if isinstance(x, (list, dict, set)):
        try:
            return json.dumps(x, sort_keys=True, ensure_ascii=False)
        except Exception:
            return str(x)
    return x

def safe_nunique(s: pd.Series) -> int:
    try:
        return s.nunique(dropna=True)
    except TypeError:
        return s.map(_serialize_cell).nunique(dropna=True)

def safe_unique_options(s: pd.Series):
    # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ option ‡πÄ‡∏õ‡πá‡∏ô string ‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
    try:
        uniq = s.dropna().unique().tolist()
    except TypeError:
        uniq = s.dropna().map(_serialize_cell).unique().tolist()
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏™‡∏°‡∏≠ (‡πÑ‡∏°‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô)
    return sorted([str(u) for u in uniq])

# -------- ‡πÅ‡∏¢‡∏Å‡∏ä‡∏ô‡∏¥‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå + ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° parse ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà --------
for c in df.columns:
    if df[c].dtype == "object":
        # parse datetime ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö
        try:
            df[c] = pd.to_datetime(df[c])
        except Exception:
            pass

num_cols = df.select_dtypes(include=["number", "float", "int"]).columns.tolist()
dt_cols  = df.select_dtypes(include=["datetime64[ns]","datetimetz"]).columns.tolist()
cat_cols = [c for c in df.columns if c not in num_cols + dt_cols]

st.subheader("üéöÔ∏è ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏î‡∏£‡∏≠‡∏õ‡∏î‡∏≤‡∏ß‡∏ô‡πå (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á)")
with st.expander("‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á"):
    # ‡πÉ‡∏ä‡πâ safe_nunique ‡πÅ‡∏ó‡∏ô .nunique ‡∏ï‡∏£‡∏á ‡πÜ
    default_filter_cols = []
    for c in cat_cols:
        try:
            if safe_nunique(df[c]) <= 100:
                default_filter_cols.append(c)
        except Exception:
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏î ‡πÜ ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏õ
            continue
    default_filter_cols = default_filter_cols[:6]

    filter_cols = st.multiselect(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏î‡∏£‡∏≠‡∏õ‡∏î‡∏≤‡∏ß‡∏ô‡πå",
        cat_cols,
        default=default_filter_cols,
        help="‡∏Ñ‡∏ß‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡πà‡∏≤‡∏à‡∏≥‡πÄ‡∏û‡∏≤‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏¢‡∏≠‡∏∞‡∏ô‡∏±‡∏Å (‚â§ ~100)"
    )

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏£‡∏≠‡∏õ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    filters = {}
    flt_cols_layout = st.columns(min(3, max(1, len(filter_cols))))
    for i, c in enumerate(filter_cols):
        options = ["(‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)"] + safe_unique_options(df[c])
        with flt_cols_layout[i % len(flt_cols_layout)]:
            sel = st.multiselect(f"{c}", options=options, default="(‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)")
        filters[c] = sel

    # ‡∏Å‡∏£‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà)
    if dt_cols:
        st.markdown("**‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)**")
        date_col = st.selectbox("‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", ["(‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ)"] + dt_cols, index=0)
        if date_col != "(‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ)":
            min_d, max_d = pd.to_datetime(df[date_col].min()), pd.to_datetime(df[date_col].max())
            d_range = st.date_input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", (min_d.date(), max_d.date()))
            if isinstance(d_range, tuple) and len(d_range) == 2:
                start_d, end_d = pd.to_datetime(d_range[0]), pd.to_datetime(d_range[1])
            else:
                start_d, end_d = min_d, max_d
        else:
            date_col = None
            start_d = end_d = None
    else:
        date_col = None
        start_d = end_d = None

# -------- ‡∏ô‡∏≥‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡πÑ‡∏õ‡πÉ‡∏ä‡πâ --------
df_filtered = df.copy()

# ‡∏Å‡∏£‡∏≠‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà (‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ö‡∏ö‡∏™‡∏ï‡∏£‡∏¥‡∏á‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)
for c, sel in filters.items():
    if sel and "(‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)" not in sel:
        df_filtered = df_filtered[df_filtered[c].map(_serialize_cell).astype(str).isin(sel)]

# ‡∏Å‡∏£‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
if date_col and start_d is not None and end_d is not None:
    df_filtered = df_filtered[
        (pd.to_datetime(df_filtered[date_col]) >= start_d) &
        (pd.to_datetime(df_filtered[date_col]) <= end_d)
    ]

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á & ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß
st.subheader("üìã ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
show_cols = st.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á", df_filtered.columns.tolist(), default=df_filtered.columns.tolist()[:10])
limit = st.slider("‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á", 10, 5000, 500)

table_df = df_filtered[show_cols] if show_cols else df_filtered
st.dataframe(table_df.head(limit), use_container_width=True, height=420)

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
st.download_button(
    "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á (CSV)",
    data=table_df.to_csv(index=False).encode("utf-8-sig"),
    file_name="filtered_table.csv",
    mime="text/csv"
)
